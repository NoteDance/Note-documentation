Use kernel to train neural network. First, you should write a neural network class that include method object and Instance object.
Method object:
Method object need to use Tensorflow 2.0 version and above to write.
1. fp(data) Receive data to forward propagation then output result.
2. loss(output,labels) Receive output and labels output loss.
3. oopt(gradient,param) and gradient(tape,loss,param) If you want to write optimizer by yourself.

Instance object:
1.If you don't want to write optimizer by yourself,assign opt as optimizer of tensorflow
2.Instance include parameter and hyper-parameter,where parameter must be named param, instance can include anything you need.


----------------------------------------------------------------------------------------
If you done your neural network,you can use kernel to train.
simple example:
import tensorflow as tf
import Note.create.kernel as k   #import kernel
import cnn as c                          #import your class's python file
mnist=tf.keras.datasets.mnist
(x_train,y_train),(x_test,y_test)=mnist.load_data()
x_train,x_test =x_train/255.0,x_test/255.0
y_train=tf.one_hot(y_train,10)
cnn=c.cnn()                                #create class object
kernel=k.kernel(cnn)                 #start kernel
kernel.data(x_train,y_train)   #input you data,if you have test data can transfer to kernel API data()
                                                          #data can be a list,[data1,data2,...,datan]
kernel.train(32,5)         #train neural network
                                    #batch: batch size
                                    #epoch:epoch


-----------------------------------------------------------------------------------------
Parallel optimization:
Use multithreading to optimize.
Note have two types of parallel optimization:
1. not parallel computing gradient and optimizing.
2. parallel computing gradient and optimizing.


Multithreadingï¼š
simple example:
import tensorflow as tf
import Note.create.kernel as k   #import kernel
import cnn as c                          #import your class's python file
import threading
mnist=tf.keras.datasets.mnist
(x_train,y_train),(x_test,y_test)=mnist.load_data()
x_train,x_test=x_train/255.0,x_test/255.0
y_train=tf.one_hot(y_train,10)
cnn=c.cnn()                                #create class object
kernel=k.kernel(cnn)   #start kernel
kernel.thread=2                                 #thread count
kernel.data(x_train,y_train)   #input you data
kernel.PO=1 or kernel.PO=2
kernel.thread_lock=threading.Lock() or kernel.thread_lock=[threading.Lock(),threading.Lock(),threading.Lock()]
class thread(threading.Thread):
	def run(self):
		kernel.train(32,3)
for _ in range(2):
	_thread=thread()
	_thread.start()
for _ in range(2):
	_thread.join()


----------------------------------------------------------------------------------------
Add threads:
add_threads(self,thread)


----------------------------------------------------------------------------------------
Save:
This kernel API can save you neural network and param as a file.
kernel.save(path)


----------------------------------------------------------------------------------------
Restore:
If you want to train your neural network again.
import Note.create.kernel as k
kernel=k.kernel()   #don't need neural network object.
kernel.restore(s_path,p_path)   #use this API to restore your neural network and param file.


-----------------------------------------------------------------------------------------
This kernel API can set end condition for training.
set_end(self,end_loss=None,end_acc=None,end_test_loss=None,end_test_acc=None)
kernel.set_end(0.7)   #use set_end() by kernel


-----------------------------------------------------------------------------------------
This kernel API can visualize your taining.
train_visual(self)
kernel.train_visual()   #use train_visual() by kernel


-----------------------------------------------------------------------------------------
Kernel's instance object:
self.nn: neural network object
self.nn.km: kernel mode
self.PO: parallel optimization
self.thread_lock: thread lock
self.thread: thread sum
self.ol: online training function be used for kernel to oniline train
self.batch: batch size
self.epoch: epoch
self.train_loss: train loss
self.train_loss_list: self.train_visual() use this instance to visualize train loss's curve
self.test_flag: test flag if you want test,make self.test_flag=True
self.total_epoch: total epoch
self.time: train time
self.total_time:total train time
self.train_data: train data
self.train_labels: train labels
self.nn.param: neural network object's param list
self.param: this instance be used for the second kind of parallel optimization,for reduce memory consumption
self.gradient: this instance be used for the second kind of parallel optimization,for reduce memory consumption
self.train_counter: count the number of times the train function has been used


-----------------------------------------------------------------------------------------
Kernel's methon object:
data(self,train_data,train_labels,test_data=None,test_labels=None): assign data for self.train_data,self.train_labels,self.test_data,self.test_labels
init(self,param=None): initialize some kernel's instance
add_threads(self,thread): add thread count
set_end(self,end_loss=None,end_acc=None,end_test_loss=None,end_test_acc=None): set end condition
apply_gradient(self,tape,opt,loss,parameter): optimize neural network
loss_acc(self,output=None,labels_batch=None,loss=None,test_batch=None,total_loss=None,total_acc=None,t=None): compute loss and acc
core_opt(self,output,loss,t=None): optimize neural network
core_opt_t(self,data,labels,t): optimize neural network by multithreading
train(self,batch=None,epoch=None,test_batch=None,file_path=None,one=True,p=None,s=None): train neural network
test(self,test_data,test_labels,batch=None,t=None): output test loss and test acc
suspend_func(self): be used to suspend training
train_visual(self): visualize train loss and train acc by matplotlib
save_p(self,path): save neural network's parameter
save(self,path,i=None,one=True): save neural network and neural network's parameter
restore(self,s_path,p_path): restore neural network and neural network's parameter
